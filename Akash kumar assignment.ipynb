{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the PDF file\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "pdf_path = 'C:\\\\Users\\\\patel\\\\Downloads\\\\Rich-Dad-Poor-Dad.pdf'\n",
    "pdf_text = read_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing and vectorizing using a pre_trained model\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a vector store\n",
    "vector_store = {}\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    vector_store[i] = sent.vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q and A\n",
    "def answer_question(question):\n",
    "    question_vector = nlp(question).vector\n",
    "\n",
    "    # Convert doc.sents to a list\n",
    "    sents_list = list(doc.sents)\n",
    "\n",
    "    # Find the most similar vector in the vector store\n",
    "    best_match_idx = max(vector_store, key=lambda i: nlp(question).similarity(nlp(sents_list[i].text)))\n",
    "\n",
    "    # Return the corresponding section or paragraph as the answer\n",
    "    return sents_list[best_match_idx].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\AppData\\Local\\Temp\\ipykernel_31616\\2126638454.py:8: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  best_match_idx = max(vector_store, key=lambda i: nlp(question).similarity(nlp(sents_list[i].text)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Mike and I heard \n",
      "what he said but didnâ€™t understand fully what he was talking about.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chat inference   (run this to talk to the bot)\n",
    "while True:\n",
    "    user_question = input(\"Ask me a question: \")\n",
    "    if user_question.lower() == 'exit':\n",
    "        break\n",
    "    answer = answer_question(user_question)\n",
    "    print(\"Answer:\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
